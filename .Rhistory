d <- cor(train_set, predictions_train)^2
e <- rmse(test_set, predictions_test)
f <- mae(test_set, predictions_test)
g <- mape(test_set, predictions_test)
h <- cor(test_set, predictions_test)^2
}
results <- c(a,b,c,d,e,f, g, h)
names(results) <- c('RMSE_train', 'MAE_train', 'MAPE_train', 'R2_train', 'RMSE_test', 'MAE_test', 'MAPE_test', 'R2_test')
return(results)
}
}
# LASSO
# Function to save model
make_lasso <- function(outcome_var, sex){
if(sex == 'male'){
trainmat <- dxa_train_male %>% select(colnames(dxa_train_male)[c(6:50, 53:69)]) %>% as.matrix()
lasso1cv <- cv.glmnet(trainmat, dxa_train_male[,outcome_var])
lam_min1 <- lasso1cv$lambda.min
lasso1 <- glmnet(trainmat, dxa_train_male[,outcome_var], lambda = lam_min1)
return(lasso1)
}
else if(sex == 'female'){
trainmat <- dxa_train_female %>% select(colnames(dxa_train_female)[c(6:50, 53:69)]) %>% as.matrix()
lasso1cv <- cv.glmnet(trainmat, dxa_train_female[,outcome_var])
lam_min1 <- lasso1cv$lambda.min
lasso1 <- glmnet(trainmat, dxa_train_female[,outcome_var], lambda = lam_min1)
return(lasso1)
}
}
# RANDOM FOREST
# Function to save model
make_rf <- function(outcome_var, sex){
if(sex == 'male'){
form <- as.formula(paste(outcome_var, '~ . -ha1q34_6dtrunk_pcent_fat - ha1q34_12dl1l4_pcent1 - ha1q34_9atotal_fat - ha1q34_9btotal_lean - ha1q34_9dtotal_pcent_fat - appendic_fat - appendic_lean'))
rf1 <- caret::train(form,
dxa_train_male,
tuneLength = 5,
method = "ranger",
trControl = trainControl(method = "cv",
number = 10,
verboseIter = FALSE))
rf1mtry <- rf1$bestTune$mtry
rf1r <- ranger(form,
dxa_train_male,
mtry = rf1mtry,
importance = 'impurity')
return(rf1r)
}
else if(sex == 'female'){
form <- as.formula(paste(outcome_var, '~ .  -ha1q34_6dtrunk_pcent_fat - ha1q34_12dl1l4_pcent1 - ha1q34_9atotal_fat - ha1q34_9btotal_lean - ha1q34_9dtotal_pcent_fat - appendic_fat - appendic_lean'))
rf1 <- caret::train(form,
dxa_train_female,
tuneLength = 5,
method = "ranger",
trControl = trainControl(method = "cv",
number = 10,
verboseIter = FALSE))
rf1mtry <- rf1$bestTune$mtry
rf1r <- ranger(form,
dxa_train_female,
mtry = rf1mtry,
importance = 'impurity')
return(rf1r)
}
}
# XGBOOST
# Function to save model
make_xgb <- function(outcome_var, sex){
if(sex == 'male'){
form <- as.formula(paste(outcome_var, '~ .  -ha1q34_6dtrunk_pcent_fat - ha1q34_12dl1l4_pcent1 - ha1q34_9atotal_fat - ha1q34_9btotal_lean - ha1q34_9dtotal_pcent_fat - appendic_fat - appendic_lean'))
xg1 <- caret::train(form,
dxa_train_male,
method = 'xgbTree',
verbosity = 0,
#objective = "reg:squarederror",
trControl = trainControl(method = "cv",
number = 10,
verboseIter = FALSE))
return(xg1)
}
else if(sex == 'female'){
form <- as.formula(paste(outcome_var, '~ .  -ha1q34_6dtrunk_pcent_fat - ha1q34_12dl1l4_pcent1 - ha1q34_9atotal_fat - ha1q34_9btotal_lean - ha1q34_9dtotal_pcent_fat - appendic_fat - appendic_lean'))
xg1 <- caret::train(form,
dxa_train_female,
method = 'xgbTree',
verbosity = 0,
#objective = "reg:squarederror",
trControl = trainControl(method = "cv",
number = 10,
verboseIter = FALSE))
return(xg1)
}
}
# Use function to get performance from elastic net models since it takes extra steps
predict_enet <- function(model, dataset){
return(as.numeric((dataset %>% select(colnames(dataset)[c(6:50, 53:69)]) %>% as.matrix() %*% model$beta) + model$a0))
}
set.seed(66)
fat_res_male = numeric(25)
fat_res_female = numeric(25)
totalfat_perm = data.frame(RMSE_train	= numeric(8),
MAE_train	= numeric(8),
MAPE_train	= numeric(8),
R2_train	= numeric(8),
RMSE_test	= numeric(8),
MAE_test	= numeric(8),
MAPE_test	= numeric(8),
R2_test	= numeric(8))
for(i in 1:25){
# Have backup copies of dataset from before permutation
dxa_train_male_save = dxa_train_male
dxa_test_male_save = dxa_test_male
dxa_train_female_save = dxa_train_female
dxa_test_female_save = dxa_test_female
# Randomly sample order for males
new_order = sample(1:(length(c(dxa_train_male[,'ha1q34_9atotal_fat'], dxa_test_male[,'ha1q34_9atotal_fat']))),
length(c(dxa_train_male[,'ha1q34_9atotal_fat'], dxa_test_male[,'ha1q34_9atotal_fat'])))
out_vec = c(dxa_train_male[,'ha1q34_9atotal_fat'], dxa_test_male[,'ha1q34_9atotal_fat'])
out_vec = out_vec[new_order]
dxa_train_male[,'ha1q34_9atotal_fat']  = out_vec[1:nrow(dxa_train_male)]
dxa_test_male[,'ha1q34_9atotal_fat']  = out_vec[(nrow(dxa_train_male)+1):length(out_vec)]
# Randomly sample order for females
new_order = sample(1:(length(c(dxa_train_female[,'ha1q34_9atotal_fat'], dxa_test_female[,'ha1q34_9atotal_fat']))),
length(c(dxa_train_female[,'ha1q34_9atotal_fat'], dxa_test_female[,'ha1q34_9atotal_fat'])))
out_vec = c(dxa_train_female[,'ha1q34_9atotal_fat'], dxa_test_female[,'ha1q34_9atotal_fat'])
out_vec = out_vec[new_order]
dxa_train_female[,'ha1q34_9atotal_fat']  = out_vec[1:nrow(dxa_train_female)]
dxa_test_female[,'ha1q34_9atotal_fat']  = out_vec[(nrow(dxa_train_female)+1):length(out_vec)]
# Models
tot_fat_male_lasso <- make_lasso('ha1q34_9atotal_fat', 'male')
tot_fat_male_rf <- make_rf('ha1q34_9atotal_fat', 'male')
tot_fat_male_xgb <- make_xgb('ha1q34_9atotal_fat', 'male')
tot_fat_female_lasso <- make_lasso('ha1q34_9atotal_fat', 'female')
tot_fat_female_rf <- make_rf('ha1q34_9atotal_fat', 'female')
tot_fat_female_xgb <- make_xgb('ha1q34_9atotal_fat', 'female')
# Performance
tfm1 <- train_test_perf(1000*dxa_train_male[,'ha1q37_5ii_tbf_mass'],
1000*dxa_test_male[,'ha1q37_5ii_tbf_mass'],
'ha1q34_9atotal_fat', 'male')
tfm2 <- train_test_perf(predict_enet(tot_fat_male_lasso, dxa_train_male),
predict_enet(tot_fat_male_lasso, dxa_test_male),
'ha1q34_9atotal_fat', 'male')
tfm3 <- train_test_perf(predict(tot_fat_male_rf, dxa_train_male)$predictions,
predict(tot_fat_male_rf, dxa_test_male)$predictions,
'ha1q34_9atotal_fat', 'male')
tfm4 <- train_test_perf(predict(tot_fat_male_xgb, dxa_train_male),
predict(tot_fat_male_xgb, dxa_test_male),
'ha1q34_9atotal_fat', 'male')
tfm5 <- train_test_perf(1000*dxa_train_female[,'ha1q37_5ii_tbf_mass'],
1000*dxa_test_female[,'ha1q37_5ii_tbf_mass'],
'ha1q34_9atotal_fat', 'female')
tfm6 <- train_test_perf(predict_enet(tot_fat_female_lasso, dxa_train_female),
predict_enet(tot_fat_female_lasso, dxa_test_female),
'ha1q34_9atotal_fat', 'female')
tfm7 <- train_test_perf(predict(tot_fat_female_rf, dxa_train_female)$predictions,
predict(tot_fat_female_rf, dxa_test_female)$predictions,
'ha1q34_9atotal_fat', 'female')
tfm8 <- train_test_perf(predict(tot_fat_female_xgb, dxa_train_female),
predict(tot_fat_female_xgb, dxa_test_female),
'ha1q34_9atotal_fat', 'female')
totalfatresults <- rbind(tfm1, tfm2, tfm3, tfm4, tfm5, tfm6, tfm7, tfm8)
# do this for some idea of SE
fat_res_male[i] = totalfatresults[2,6]
fat_res_female[i] = totalfatresults[6,6]
totalfat_perm = totalfat_perm + totalfatresults
# revert datasets to unpermuted version
dxa_train_male = dxa_train_male_save
dxa_test_male = dxa_test_male_save
dxa_train_female = dxa_train_female_save
dxa_test_female = dxa_test_female_save
print(i)
}
totalfatresults = totalfat_perm / 25
totalfatresults[,1] <- round(totalfatresults[,1]/1000, 2)
totalfatresults[,2] <- round(totalfatresults[,2]/1000, 3)
totalfatresults[,3] <- round(totalfatresults[,3]*100, 2)
totalfatresults[,4] <- round(totalfatresults[,4], 3)
totalfatresults[,5] <- round(totalfatresults[,5]/1000, 2)
totalfatresults[,6] <- round(totalfatresults[,6]/1000, 3)
totalfatresults[,7] <- round(totalfatresults[,7]*100, 2)
totalfatresults[,8] <- round(totalfatresults[,8], 3)
sd(fat_res_male/1000)
sd(fat_res_female/1000)
write.csv(totalfatresults, 'totalfatmasslessints_perm3.csv')
# Generate dataset
somedata = data_gen_mlna_cfs(n_clust = 1000,
n_mid_clust = 100,
clust_size = 100,
outcome_int = 0,
trt_effect = 1,
clust_outcome_coefs = c(1, 0),
midclust_outcome_coefs = c(0, 0),
indiv_outcome_coefs = c(0.5, 0.5),
adhere_int = 0,
clust_adhere_coefs = c(0.5, 0.5),
midclust_adhere_coefs = c(0, 0),
indiv_adhere_coefs = c(0.5, 0.5),
out_clust_var = 1,
out_mid_var = 0,
out_ind_var = NA,
adh_clust_var = 1,
adh_mid_var = 0,
outcome_type = "binary")
# Source in the function needed to generate the data
source("~/cluster_sandbox/Multilevel Experiment/data_gen_fns.R")
# Generate dataset
somedata = data_gen_mlna_cfs(n_clust = 1000,
n_mid_clust = 100,
clust_size = 100,
outcome_int = 0,
trt_effect = 1,
clust_outcome_coefs = c(1, 0),
midclust_outcome_coefs = c(0, 0),
indiv_outcome_coefs = c(0.5, 0.5),
adhere_int = 0,
clust_adhere_coefs = c(0.5, 0.5),
midclust_adhere_coefs = c(0, 0),
indiv_adhere_coefs = c(0.5, 0.5),
out_clust_var = 1,
out_mid_var = 0,
out_ind_var = NA,
adh_clust_var = 1,
adh_mid_var = 0,
outcome_type = "binary")
# Establish column names to be easier to work with
colnames(somedata) = c("int", "arm", "L1", "L2", "gammas_out", "cluster", "M1", "M2",
"zetas_out", "midcluster", "X1", "X2", "indiv", "treated", "Y1", "Y0" , "Y",
"adhere", "adhere_lp", "gammas_adh", "zetas_adh")
# True mean Y1-Y0, ie ACE
ace_true = mean(somedata$Y1 - somedata$Y0)
ace_true
0.1662429-0.1658574
# Load packages
library(MASS)
library(tidyverse)
library(gee)
library(nlme)
library(geepack)
library(lme4)
library(glmm)
library(lmerTest)
library(ivtools)
# Source in the function needed to generate the data
source("~/cluster_sandbox/Multilevel Experiment/data_gen_fns.R")
# New function for freeman estimates given model and treated/untreated datasets
freedman <- function(my_mod, somedata_t1, somedata_t0){
log(mean(expit(predict(my_mod, somedata_t1)))/(1 - (mean(expit(predict(my_mod, somedata_t1)))))) - log(mean(expit(predict(my_mod, somedata_t0)))/(1 - (mean(expit(predict(my_mod, somedata_t0))))))
}
#################################
# CASE 1: Midcluster is irrelevant
#################################
# Here, random intercept variance will be 0
# No confounders should exit
set.seed(42425)
# Generate dataset
somedata = data_gen_mlna_cfs(n_clust = 1000,
n_mid_clust = 100,
clust_size = 100,
outcome_int = 0,
trt_effect = 1,
clust_outcome_coefs = c(1, 0),
midclust_outcome_coefs = c(0, 0),
indiv_outcome_coefs = c(0.5, 0.5),
adhere_int = 0,
clust_adhere_coefs = c(0.5, 0.5),
midclust_adhere_coefs = c(0, 0),
indiv_adhere_coefs = c(0.5, 0.5),
out_clust_var = 1,
out_mid_var = 0,
out_ind_var = NA,
adh_clust_var = 1,
adh_mid_var = 0,
outcome_type = "binary")
# This dataset has 10 million observations!
# Establish column names to be easier to work with
colnames(somedata) = c("int", "arm", "L1", "L2", "gammas_out", "cluster", "M1", "M2",
"zetas_out", "midcluster", "X1", "X2", "indiv", "treated", "Y1", "Y0" , "Y",
"adhere", "adhere_lp", "gammas_adh", "zetas_adh")
# True mean Y1-Y0, ie ACE
ace_true = mean(somedata$Y1 - somedata$Y0)
# 0.1658574
# DXA TANITA Permutation test
# Per the suggestions of one reviewer
# Data processing will be the same,
# Model fitting also generally the same
# But outcome values will randomly be permuted
library(readstata13)
library(tidyverse)
library(mice)
library(caret)
library(ranger)
library(glmnet)
library(Metrics)
library(blandr)
library(gridExtra)
# Import data
wave3 <- read.dta13('~/Downloads/3FU_for share_Nick.dta')
wave3_plus <- read.dta13('~/Downloads/extract_forNick_070721.dta')
wave3 <- left_join(wave3, wave3_plus, by = 'ha1id')
# DXA Variables
summary(wave3$ha1q34_10al1l4_fat1) #   L1-L4 fat Reading1 (g)
summary(wave3$ha1q34_10bl1l4_lean1) #   L1-L4 lean Reading1 (g)
summary(wave3$ha1q34_10cl1l4_mass1) #   L1-L4 mass Reading1 (g)
summary(wave3$ha1q34_10dl1l4_pcent1) #   L1-L4 % body fat Reading1 (g)
summary(wave3$ha1q34_11al2l4_fat1) #   L2-L4 fat Reading1 (g)
summary(wave3$ha1q34_11bl2l4_lean1)
summary(wave3$ha1q34_11cl2l4_mass1) # MAX here seems like a data entry error.
summary(wave3$ha1q34_11dl2l4_pcent1)
summary(wave3$ha1q34_12al1l4_fat1) #   L1-L4 fat Reading2 (g)
summary(wave3$ha1q34_12bl1l4_lean1)
summary(wave3$ha1q34_12cl1l4_mass1)
summary(wave3$ha1q34_12dl1l4_pcent1)
summary(wave3$ha1q34_13al2l4_fat1) #   L2-L4 fat Reading2 (g)
summary(wave3$ha1q34_13bl2l4_lean1)
summary(wave3$ha1q34_13cl2l4_mass1)
summary(wave3$ha1q34_13dl2l4_pcent1)
summary(wave3$ha1q34_4alarm_fat) #   Left arm fat (g)
summary(wave3$ha1q34_4blarm_lean) #   Left arm lean (g)
summary(wave3$ha1q34_4clarm_mass) #   Left arm mass (g)
summary(wave3$ha1q34_4dlarm_pcent_fat) #   Left arm % body fat
summary(wave3$ha1q34_5ararm_fat)
summary(wave3$ha1q34_5brarm_lean)
summary(wave3$ha1q34_5crarm_mass)
summary(wave3$ha1q34_5drarm_pcent_fat)
summary(wave3$ha1q34_6atrunk_fat)
summary(wave3$ha1q34_6btrunk_lean)
summary(wave3$ha1q34_6ctrunk_mass)
summary(wave3$ha1q34_6dtrunk_pcent_fat)
summary(wave3$ha1q34_7alleg_fat)
summary(wave3$ha1q34_7blleg_lean)
summary(wave3$ha1q34_7clleg_mass) # I suspect typos here?
summary(wave3$ha1q34_7dlleg_pcent_fat)
summary(wave3$ha1q34_8arleg_fat)
summary(wave3$ha1q34_8brleg_lean)
summary(wave3$ha1q34_8crleg_mass)
summary(wave3$ha1q34_8drleg_pcent_fat)
summary(wave3$ha1q34_9atotal_fat)
summary(wave3$ha1q34_9btotal_lean)
summary(wave3$ha1q34_9ctotal_mass)
summary(wave3$ha1q34_9dtotal_pcent_fat)
# 3718 people have data for both variables (TANITA and DXA)
table(is.na(wave3$ha1q37_10i_seg_la_pcent), is.na(wave3$ha1q34_10al1l4_fat1))
# will build on this paper:
# https://www.researchgate.net/publication/255959062_Development_and_validation_of_anthropometric_prediction_equations_for_estimation_of_lean_body_mass_and_appendicular_lean_soft_tissue_in_Indian_men_and_women
# "DXA-measured LBM and ALST estimates as dependent variables"
# (LBM = lean body mass and ALST = appendicular lean soft tissue)
# Their unit was kg, so total mass it seems
# ALST is used for sarcopenia definition, approximates skeletal mass
# TANITA Variables
summary(wave3$ha1q37_10i_seg_la_pcent) #   Segmental analysis: Left Arm: Fat percentage(%)
summary(wave3$ha1q37_10ii_seg_la_mass) #   Segmental analysis: Left Arm: Fat mass Kg
summary(wave3$ha1q37_10iii_seg_la_free_mass) #   Segmental analysis: Left Arm: Fat free mass Kg
summary(wave3$ha1q37_10iv_seg_la_muscle) #   Segmental analysis: Left Arm: Pred muscle mass Kg
summary(wave3$ha1q37_11i_seg_tr_pcent) #   Segmental analysis: Trunk: Fat percentage(%)
summary(wave3$ha1q37_11ii_seg_tr_mass) #   Segmental analysis: Trunk: Fat mass Kg
summary(wave3$ha1q37_11iii_seg_tr_free_mass) #   Segmental analysis: Trunk: Fat free mass Kg
summary(wave3$ha1q37_11iv_seg_tr_muscle) #   Segmental analysis: Trunk: Pred muscle mass Kg
summary(wave3$ha1q37_2_weight)
summary(wave3$ha1q37_3_bmi)
summary(wave3$ha1q37_4a_bmr_kj)
summary(wave3$ha1q37_4b_bmr_kcal)
summary(wave3$ha1q37_5i_tbf_pcent) #   Total Body Fat: Fat percentage(%)
summary(wave3$ha1q37_5ii_tbf_mass) #   Total Body Fat: Fat mass Kg
summary(wave3$ha1q37_5iii_tbf_free_mass) #   Total Body Fat: Fat free mass Kg
summary(wave3$ha1q37_5iv_tbf_water) #   Total Body Fat: Total body water Kg
summary(wave3$ha1q37_6i_imp_whole_body)
summary(wave3$ha1q37_6ii_imp_rleg)
summary(wave3$ha1q37_6iii_imp_lleg)
summary(wave3$ha1q37_6iv_imp_rarm)
summary(wave3$ha1q37_6v_imp_larm)
summary(wave3$ha1q37_7i_seg_rl_pcent) #   Segmental analysis: Right Leg: Fat percentage(%)
summary(wave3$ha1q37_7ii_seg_rl_mass) #   Segmental analysis: Right Leg: Fat mass Kg
summary(wave3$ha1q37_7iii_seg_rl_free_mass) #   Segmental analysis: Right Leg: Fat free mass Kg
summary(wave3$ha1q37_7iv_seg_rl_muscle) #   Segmental analysis: Right Leg: Pred muscle mass Kg
summary(wave3$ha1q37_8i_seg_ll_pcent)
summary(wave3$ha1q37_8ii_seg_ll_mass)
summary(wave3$ha1q37_8iii_seg_ll_free_mass)
summary(wave3$ha1q37_8iv_seg_ll_muscle)
summary(wave3$ha1q37_9i_seg_ra_pcent)
summary(wave3$ha1q37_9ii_seg_ra_mass)
summary(wave3$ha1q37_9iii_seg_ra_free_mass)
summary(wave3$ha1q37_9iv_seg_ra_muscle)
# Circumferences
summary(wave3$ha1q25_10acalf_circ1)
summary(wave3$ha1q25_10bcalf_circ2)
summary(wave3$ha1q25_11ahead_circ1)
summary(wave3$ha1q25_11bhead_circ2)
summary(wave3$ha1q25_11iachest_i_circ1) #   Chest circumference at end of inspiration1(mm)
summary(wave3$ha1q25_11ibchest_i_circ2)
summary(wave3$ha1q25_11iiachest_e_circ1) #   Chest circumference at end of expiration(mm)
summary(wave3$ha1q25_11iibchest_e_circ2)
summary(wave3$ha1q25_7awaist_circ1)
summary(wave3$ha1q25_7bwaist_circ2)
summary(wave3$ha1q25_8ahip_circ1)
summary(wave3$ha1q25_8bhip_circ2)
summary(wave3$ha1q25_9aarm_circ1)
summary(wave3$ha1q25_9barm_circ2)
# Skin Folds
summary(wave3$ha1q25_12atricep1)
summary(wave3$ha1q25_12btricep2)
summary(wave3$ha1q25_12ctricep3)
summary(wave3$ha1q25_13abicep1)
summary(wave3$ha1q25_13bbicep2)
summary(wave3$ha1q25_13cbicep3)
summary(wave3$ha1q25_14asubscap1)
summary(wave3$ha1q25_14bsubscap2)
summary(wave3$ha1q25_14csubscap3)
summary(wave3$ha1q25_15asupra1)
summary(wave3$ha1q25_15bsupra2)
summary(wave3$ha1q25_15csupra3)
summary(wave3$ha1q25_16acalf1)
summary(wave3$ha1q25_16bcalf2)
summary(wave3$ha1q25_16ccalf3)
# Grip strength
summary(wave3$ha1q25_18hand1_strgthr)
summary(wave3$ha1q25_18hand2_strgthr)
summary(wave3$ha1q25_18hand3_strgthr)
summary(wave3$ha1q25_18hand4_strgthr)
summary(wave3$ha1q25_19hand1_strgthl)
summary(wave3$ha1q25_19hand2_strgthl) # Some VERY high values here? 1-3, but not 4.
summary(wave3$ha1q25_19hand3_strgthl)
summary(wave3$ha1q25_19hand4_strgthl)
table(wave3$ha1q25_20dom_hand) # 1 = right, 2 = left
# Standing height
summary(wave3$ha1q25_3astand_height1)
summary(wave3$ha1q25_3bstand_height2)
# Next steps are as follows:
# First, split into training and testing
# To split the data, should filter out the records with NO data
# As these people are not part of the study
table(is.na(wave3$ha1q5_5sex)) # 7460 NA, 6928 have data
# Also exclude people younger than 18?
# AND in this case, exclude NA from the variables we are using
# THIS IS THE SLIGHTLY MODIFIED SCRIPT WHERE WE USE AVERAGE OF 2 L1-L4
# CORRECT NOW TO AVOID ISSUES LATER
wave3 <- wave3 %>% mutate(ha1q34_12dl1l4_pcent1 = (ha1q34_10dl1l4_pcent1 + ha1q34_12dl1l4_pcent1)/2)
our_variables <- c('ha1q34_9atotal_fat', 'ha1q34_9btotal_lean', 'ha1q34_9dtotal_pcent_fat',
'ha1q34_6dtrunk_pcent_fat',
'ha1q34_12dl1l4_pcent1',
'ha1q34_4alarm_fat', 'ha1q34_4blarm_lean', 'ha1q34_5ararm_fat', 'ha1q34_5brarm_lean',
'ha1q34_7alleg_fat', 'ha1q34_7blleg_lean', 'ha1q34_8arleg_fat', 'ha1q34_8brleg_lean',
# Predictors
'ha1q37_10i_seg_la_pcent',
'ha1q37_10ii_seg_la_mass', 'ha1q37_10iii_seg_la_free_mass', 'ha1q37_10iv_seg_la_muscle',
'ha1q37_11i_seg_tr_pcent', 'ha1q37_11ii_seg_tr_mass', 'ha1q37_11iii_seg_tr_free_mass',
'ha1q37_11iv_seg_tr_muscle', 'ha1q37_2_weight', 'ha1q37_3_bmi', 'ha1q37_4a_bmr_kj',
'ha1q37_4b_bmr_kcal', 'ha1q37_5i_tbf_pcent', 'ha1q37_5ii_tbf_mass',
'ha1q37_5iii_tbf_free_mass', 'ha1q37_5iv_tbf_water', 'ha1q37_6i_imp_whole_body',
'ha1q37_6ii_imp_rleg', 'ha1q37_6iii_imp_lleg', 'ha1q37_6iv_imp_rarm',
'ha1q37_6v_imp_larm', 'ha1q37_7i_seg_rl_pcent', 'ha1q37_7ii_seg_rl_mass',
'ha1q37_7iii_seg_rl_free_mass', 'ha1q37_7iv_seg_rl_muscle', 'ha1q37_8i_seg_ll_pcent',
'ha1q37_8ii_seg_ll_mass', 'ha1q37_8iii_seg_ll_free_mass', 'ha1q37_8iv_seg_ll_muscle',
'ha1q37_9i_seg_ra_pcent', 'ha1q37_9ii_seg_ra_mass', 'ha1q37_9iii_seg_ra_free_mass',
'ha1q37_9iv_seg_ra_muscle', 'ha1q25_10acalf_circ1', 'ha1q25_10bcalf_circ2',
'ha1q25_11ahead_circ1', 'ha1q25_11bhead_circ2', 'ha1q25_11iachest_i_circ1',
'ha1q25_11ibchest_i_circ2', 'ha1q25_11iiachest_e_circ1', 'ha1q25_11iibchest_e_circ2',
'ha1q25_7awaist_circ1', 'ha1q25_7bwaist_circ2', 'ha1q25_8ahip_circ1',
'ha1q25_8bhip_circ2', 'ha1q25_9aarm_circ1', 'ha1q25_9barm_circ2', 'ha1q25_12atricep1',
'ha1q25_12btricep2', 'ha1q25_12ctricep3', 'ha1q25_13abicep1', 'ha1q25_13bbicep2',
'ha1q25_13cbicep3', 'ha1q25_14asubscap1', 'ha1q25_14bsubscap2', 'ha1q25_14csubscap3',
'ha1q25_15asupra1', 'ha1q25_15bsupra2', 'ha1q25_15csupra3', 'ha1q25_16acalf1',
'ha1q25_16bcalf2', 'ha1q25_16ccalf3', 'ha1q25_18hand1_strgthr', 'ha1q25_18hand2_strgthr',
'ha1q25_18hand3_strgthr', 'ha1q25_18hand4_strgthr', 'ha1q25_19hand1_strgthl',
'ha1q25_19hand2_strgthl', 'ha1q25_19hand3_strgthl', 'ha1q25_19hand4_strgthl', 'ha1q25_20dom_hand',
'ha1q25_3astand_height1', 'ha1q25_3bstand_height2')
wave3 <- wave3 %>% filter(across(c(ha1q5_5sex, our_variables), ~ !is.na(.)))
wave3 <- wave3 %>% filter(ha1dv_age >= 18)
# Filter out for data quality issues
wave3 <- wave3 %>% filter(!(ha1q25_11ahead_circ1 < 450 | ha1q25_11bhead_circ2 < 450))
wave3 <- wave3 %>% filter(ha1q25_18hand1_strgthr < 100 &
ha1q25_18hand2_strgthr < 100 &
ha1q25_18hand3_strgthr < 100 &
ha1q25_18hand4_strgthr < 100 &
ha1q25_19hand1_strgthl < 100 &
ha1q25_19hand2_strgthl < 100 &
ha1q25_19hand3_strgthl < 100 &
ha1q25_19hand4_strgthl < 100)
wave3 <- wave3 %>% filter(ha1q37_5i_tbf_pcent < 50 & ha1q34_9dtotal_pcent_fat < 50)
wave3 <- wave3 %>% filter((abs(ha1q37_2_weight - ha1q37_5ii_tbf_mass - ha1q37_5iii_tbf_free_mass) < 1))
# muscle cannot be greater than fat free mass
wave3 <- wave3 %>% filter(ha1q37_11iv_seg_tr_muscle <= ha1q37_11iii_seg_tr_free_mass)
wave3 <- wave3 %>% filter(ha1q37_10iv_seg_la_muscle <= ha1q37_10iii_seg_la_free_mass)
wave3 <- wave3 %>% filter(ha1q37_9iv_seg_ra_muscle <= ha1q37_9iii_seg_ra_free_mass)
wave3 <- wave3 %>% filter(ha1q37_8iv_seg_ll_muscle <= ha1q37_8iii_seg_ll_free_mass)
wave3 <- wave3 %>% filter(ha1q37_7iv_seg_rl_muscle <= ha1q37_7iii_seg_rl_free_mass)
# component sum cannot be very different from total
wave3 <- wave3 %>% filter(abs(ha1q37_5ii_tbf_mass - ha1q37_7ii_seg_rl_mass - ha1q37_8ii_seg_ll_mass - ha1q37_9ii_seg_ra_mass - ha1q37_10ii_seg_la_mass - ha1q37_11ii_seg_tr_mass) < 1)
wave3 <- wave3 %>% filter(abs(ha1q37_5iii_tbf_free_mass - ha1q37_7iii_seg_rl_free_mass - ha1q37_8iii_seg_ll_free_mass - ha1q37_9iii_seg_ra_free_mass - ha1q37_10iii_seg_la_free_mass - ha1q37_11iii_seg_tr_free_mass) < 1)
wave3 <- wave3 %>% filter(abs(ha1q34_9atotal_fat - ha1q34_8arleg_fat - ha1q34_7alleg_fat - ha1q34_6atrunk_fat - ha1q34_5ararm_fat - ha1q34_4alarm_fat) < 2000)
wave3 <- wave3 %>% filter(abs(ha1q34_9btotal_lean - ha1q34_8brleg_lean - ha1q34_7blleg_lean - ha1q34_6btrunk_lean - ha1q34_5brarm_lean - ha1q34_4blarm_lean) < 5000)
wave3 <- wave3 %>% filter(abs(ha1q34_9ctotal_mass - ha1q34_8crleg_mass - ha1q34_7clleg_mass - ha1q34_6ctrunk_mass - ha1q34_5crarm_mass - ha1q34_4clarm_mass) < 7000)
# body cannot be less than 10% water
wave3 <- wave3 %>% filter(ha1q37_5iv_tbf_water > 10)
# some people have highly different left and right limb values
wave3 <- wave3 %>% filter(abs(wave3$ha1q37_7iv_seg_rl_muscle - wave3$ha1q37_8iv_seg_ll_muscle) < 5)
# extreme impedance values
wave3 <- wave3 %>% filter(ha1q37_6i_imp_whole_body > 100)
wave3 <- wave3 %>% filter(ha1q37_6v_imp_larm < 1000)
wave3 <- wave3 %>% filter(ha1q37_6iv_imp_rarm < 1000) # no arms less than 100
# no legs less than 100 or above 1000
# Difference in weight between scale and Tanita OR DXA
# Cannot be more than 3kg
wave3 <- wave3 %>% mutate(newweight = (ha1q25_1aweight1 + ha1q25_1bweight2)/2) %>%
filter(abs(newweight - ha1q34_9ctotal_mass/1000) < 3 & abs(newweight - ha1q37_2_weight) < 3)
# SPLIT DATA
set.seed(92)
# Let's try an 80/20 split
train_ids <- sample(1:nrow(wave3), size = round(0.8*nrow(wave3)))
dxa_train <- wave3[train_ids,]
dxa_test <- wave3[-train_ids,]
# add 'ha1q5_5sex' and age
dxa_train <- dxa_train %>% select(all_of(our_variables), 'ha1q5_5sex', 'ha1dv_age')
